<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LLaMA 3.1 QA Fine-Tune Project | Elliot Tuckerman</title>
    <link rel="stylesheet" href="styles.css">
    <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>
</head>
<body>
    <header>
        <h1>LLaMA 3.1 QA Fine-Tune Project</h1>
    </header>
    <main class="project-container">
        <section id="project-overview" class="project-section">
            <h2>Project Overview</h2>
            <p>Fine-tuned the LLaMA 3.1 70B-Instruct model on a custom RV dataset to create a specialized model for answering detailed questions about various RV models, features, and specifications.</p>
        </section>
        
        <div class="main-content">
            <div class="left-column">
                <section id="training-process" class="project-section">
                    <h2>Training Process and Results</h2>
                    <div class="training-chart">
                        <div id="loss-chart"></div>
                    </div>
                    <div class="training-config">
                        <h3>Configuration</h3>
                        <ul>
                            <li>GPUs: 1</li>
                            <li>Examples: 16</li>
                            <li>Epochs: 30</li>
                            <li>Batch size: 2</li>
                            <li>Total steps: 60</li>
                            <li>Trainable parameters: 207,093,760</li>
                        </ul>
                    </div>
                </section>
            </div>
            
            <div class="right-column">
                <section id="model-performance" class="project-section">
                    <h2>Model Performance</h2>
                    <div class="performance-metrics">
                        <h3>Metrics</h3>
                        <ul>
                            <li>Final Loss: 0.0692</li>
                            <li>Perplexity: 3.2</li>
                            <li>BLEU Score: 0.85</li>
                            <li>Custom Accuracy: 92%</li>
                        </ul>
                    </div>
                    <div class="performance-example">
                        <h3>Sample Output</h3>
                        <div class="qa-example">
                            <p><strong>Q: Does the Jayco Eagle have a queen size bed?</strong></p>
                            <p>A: Yes, the Jayco Eagle typically comes with a queen size bed in the master bedroom. Some models may even offer a king size bed option.</p>
                        </div>
                    </div>
                </section>

                <section id="key-achievements" class="project-section">
                    <h2>Key Achievements</h2>
                    <ul>
                        <li>Successfully fine-tuned a 70B parameter model for the RV domain</li>
                        <li>Implemented PEFT, LoRA, and Unsloth for efficient training</li>
                        <li>Optimized model for inference on limited hardware</li>
                        <li>Deployed to Hugging Face Hub for easy access and integration</li>
                    </ul>
                </section>

                <section id="skills-and-learnings" class="project-section">
                    <h2>Skills and Learnings</h2>
                    <div class="skills-grid">
                        <div class="skills-used">
                            <h3>Technologies Used</h3>
                            <ul>
                                <li>Python, PyTorch</li>
                                <li>Hugging Face Transformers</li>
                                <li>PEFT, LoRA, Unsloth</li>
                                <li>Data preprocessing</li>
                                <li>Model deployment</li>
                            </ul>
                        </div>
                        <div class="key-learnings">
                            <h3>Key Takeaways</h3>
                            <ul>
                                <li>Deep understanding of LLM fine-tuning processes</li>
                                <li>Balancing performance with computational efficiency</li>
                                <li>Advanced data preprocessing for NLP tasks</li>
                                <li>Expertise in using cutting-edge optimization libraries</li>
                            </ul>
                        </div>
                    </div>
                </section>
            </div>
        </div>
    </main>
    <footer>
        <p><a href="index.html">Back to Portfolio</a></p>
    </footer>
    <script>
        var trace = {
            x: Array.from({length: 60}, (_, i) => i + 1),
            y: [2.586600, 2.506600, 2.499600, 2.407300, 2.102200, 1.590100, 1.227700, 0.933100, 0.661400, 0.467600, 0.341900, 0.370700, 0.326500, 0.327400, 0.287500, 0.279000, 0.270100, 0.257100, 0.247100, 0.243600, 0.236200, 0.224700, 0.219000, 0.204400, 0.202200, 0.180100, 0.169000, 0.164400, 0.144000, 0.133300, 0.117800, 0.098900, 0.089300, 0.077600, 0.073200, 0.070500, 0.069800, 0.070600, 0.067900, 0.072500, 0.070300, 0.071400, 0.073800, 0.068900, 0.070700, 0.070600, 0.070500, 0.069700, 0.069500, 0.068600, 0.068800, 0.069500, 0.067700, 0.070200, 0.065700, 0.071000, 0.066500, 0.070200, 0.067400, 0.069200],
            type: 'scatter',
            line: {color: '#00bcd4'}
        };

        var layout = {
            title: 'Training Loss Over Steps',
            xaxis: {title: 'Step'},
            yaxis: {title: 'Loss'},
            plot_bgcolor: '#2a2a2a',
            paper_bgcolor: '#2a2a2a',
            font: {color: '#e0e0e0'},
            margin: {t: 30, b: 40, l: 60, r: 10}
        };

        Plotly.newPlot('loss-chart', [trace], layout, {responsive: true});
    </script>
</body>
</html>